use crate::error::Error;
use logos::Logos;

#[derive(Logos, Debug, PartialEq, Clone)]
pub enum Token {
    #[token("(")]
    LeftParen,

    #[token(")")]
    RightParen,

    #[token("'")]
    Quote,

    #[token("#t")]
    #[token("#true")]
    TrueValue,

    #[token("#f")]
    #[token("#false")]
    FalseValue,

    #[regex(r"[a-zA-Z!$%&*/:<=>?^_~+\-][a-zA-Z0-9!$%&*/:<=>?^_~+\-\.]*", priority = 1, callback = |lex| lex.slice().to_string())]
    Symbol(String),

    #[regex(r"-?[0-9]+(\.[0-9]+)?", priority = 2, callback = |lex| lex.slice().to_string())]
    Number(String),

    #[regex(r#""([^"\\]|\\t|\\n|\\")*""#, callback = |lex| {
        let slice = lex.slice();
        let content = &slice[1..slice.len() - 1];
        content.to_string()
    })]
    String(String),

    #[regex(r#"#\\(space|newline|.)"#, callback = |lex| {
        let slice = lex.slice();
        let content = &slice[2..];
        content.to_string()
    })]
    Character(String),

    // Skip whitespace and comments
    #[regex(r"[ \t\n\r]+", logos::skip)]
    #[regex(r";[^\n]*", logos::skip)]
    // Error token is automatically generated by Logos 0.13+
    Error,
}

pub fn lex(input: &str) -> Result<Vec<Token>, Error> {
    let lexer = Token::lexer(input);
    let mut tokens = Vec::new();

    for token_result in lexer {
        match token_result {
            Ok(token) => tokens.push(token),
            Err(_) => return Err(Error::Lexer("Invalid input".to_string())),
        }
    }

    Ok(tokens)
}
